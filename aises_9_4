<h1 id="sec:compute-gov"> 9.4 Compute Governance</h1>
<p>A common shorthand for computational resources or computing power
used for AI is <em>compute</em>. In this section, we will discuss how
compute governance enables AI governance. First, we will examine how
since compute is indispensable for AI development, governing it would
help us govern AIs. Then, we will examine the key properties of compute
that make it governable—–physicality, excludability, and
quantifiability–—and consider why governing compute is more promising
than governing other factors used in AI production.<br />
</p>
<h2
id="compute-is-indispensable-for-ai-development-and-deployment"> 9.4.1 Compute
Is Indispensable for AI Development and Deployment</h2>
<p>Compute enables the development of more capable AIs. In addition,
compute is necessary to deploy AIs. If we restrict someone’s access to
compute, they cannot develop or deploy any AIs. As a result, we can use
compute to govern AIs, determining how and when they are deployed.</p>
<p><strong>Hardware is necessary for AI systems.</strong> Like the
uranium in a nuclear weapon, compute is fundamental to running AIs. In
its simplest form, we can think of compute as a select group of
high-performance chips like GPUs and TPUs that are designed to run
modern AIs. These are often the latest chips, tailor-made for AI tasks
and found in large data centers. As AI technology changes, so too will
the hardware, adapting to new tech developments, regulations, and the
evolving requirements of AI applications.</p>
<p><strong>The metric FLOP/s is common across forms of compute.</strong>
To measure compute, we often use the metric <em>FLOP/s</em>, which is
the number of floating-point operations (such as addition or
multiplication) a computer can do in a second. When we talk about
“increasing” compute, we’re referring to using more processors, using
better processors, or allowing these processors to run for extended
periods, effectively increasing the number of floating-point operations
done in total. An analogous escalation of this is improving a nuclear
arsenal by adding more weapons to it, developing more dangerous weapons
like H-bombs, or creating bigger bombs by using more uranium.</p>
<p><strong>More compute allows for the development of more AI
capabilities.</strong> Compute plays a pivotal role in the evolution of
AI capabilities. More compute means that AI systems can be built with
more parameters and effectively utilize larger datasets. In the chapter,
we looked at scaling laws, which show us that many AIs have their
performance increase reliably with an increase in model size and dataset
size. Richard Sutton’s “The Bitter Lesson” states that general methods
in AI that harness computation tend to be the most effective by a
significant margin <span class="citation"
data-cites="Sutton-bitter"></span>. Having more compute means training
AI systems that are more capable and advanced, which means that knowing
how much compute an AI uses lets us approximate its capabilities.<br />
Often, pushing the boundaries in AI development requires having vast
compute. AIs can require training on large supercomputers that cost
hundreds of millions or even billions of dollars. Moreover,
computational demands for these AI models are constantly intensifying,
with their compute requirements doubling roughly every six months. This
growth rate surpasses the 2.5-year doubling time we see for the
price-performance of AI chips <span class="citation"
data-cites="amodei2018ai"></span>. Given this trend, it’s likely that
future AI models will demand even greater investment in computational
resources and, in turn, possess greater capabilities.</p>
<p><strong>More compute enables better results.</strong> Compute is not
only essential in training AI-—it is also necessary to run powerful AI
models effectively. Just as we rely on our brains to think and make
decisions even after we’ve learned, AI models need compute to process
information and execute tasks even after training. If developers have
access to more compute, they can run bigger models. Since bigger models
usually yield better results, having more compute can enable better
results.</p>
<p><strong>Large-scale compute isn’t a strict requirement for all future
AI applications.</strong> AI efficiency research aims to reduce compute
requirements while preserving performance by improving other factors
like algorithmic efficiency. If algorithms become so refined that
high-capability systems can train on less powerful devices, compute’s
significance for governance might diminish. Some existing systems like
AI-powered drug discovery tools do not require much compute, but it has
been demonstrated that they be can repurposed to create chemical weapons
<span class="citation" data-cites="Urbina2022DualUO"></span>.<br />
Additionally, there’s continued interest towards creating efficient AI
models capable of running on everyday devices such as smartphones and
laptops. Though projections from current trends suggest it will be
decades before data center-bound systems like GPT-4 could train on a
basic GPU <span class="citation" data-cites="epoch2023mltrends"></span>,
the shift towards greater efficiency might speed up dramatically with
just a few breakthroughs. If AI models require less compute, especially
to the point that they become commonplace on consumer devices,
regulating AI systems based on compute access might not be the most
effective approach.</p>
<h2 id="compute-is-physical-excludable-and-quantifiable"> 9.4.2 Compute Is
Physical, Excludable, and Quantifiable</h2>
<p>To produce AI, developers need three primary factors: data,
algorithms, and compute. In this section, we will explore why governing
compute appears to be a more promising avenue than governing the other
factors. A resource is governable when the entity with legitimate claims
to control it—–such as a government–—has the ability to control and
direct it. Compute is governable because</p>
<ol>
<li><p>It can be determined who has access to compute and how they
utilize it.</p></li>
<li><p>It is possible to establish and enforce specific rules about
compute.</p></li>
</ol>
<p>These are true because compute is <em>physical</em>,
<em>excludable</em>, and <em>quantifiable</em>. These characteristics
allow us to govern compute, making it a potential point of control in
the broader domain of AI governance. We will now consider each of these
in turn.</p>
<h3 id="compute-is-physical">Compute Is Physical</h3>
<p>The first key characteristic that makes compute governable is its
physicality. Compute is physical, unlike datasets, which are virtual, or
algorithms, which are intangible ideas. This makes compute rivalrous and
enables tracking and monitoring, both of which are crucial to
governance.</p>
<p><strong>Since compute is physical, it is rivalrous.</strong> Compute
is rivalrous: it cannot be used by multiple entities simultaneously.
This is unlike other factors in AI production, such as algorithms which
can be used by anyone who knows them or data which can be acquired from
the same source or even stolen or copied and used simultaneously
(although this may be difficult due to information security and the size
of training datasets). Because compute cannot be simultaneously accessed
by multiple users or easily duplicated, regulators can be confident that
when it is being used by an approved entity, it is not also being used
by someone else. This makes it easier to regulate and control the use of
compute. GPUs can’t be downloaded but instead must be fabricated,
purchased, and shipped.</p>
<div class="wrapfigure">
<p><span>r</span><span>8.4cm</span> <img
src="images/governance/image1.png" style="width:8.4cm"
alt="image" /></p>
</div>
<p><strong>Since compute is physical, it is trackable.</strong> Compute
is trackable, from chip fabrication to its use in data centers. This is
because compute is tangible and often sizable: figure <a
href="#wrap-fig:governance" data-reference-type="ref"
data-reference="wrap-fig:governance">[wrap-fig:governance]</a> shows a
cutting-edge semiconductor tool used as compute that costs $200 million
and requires 40 freight containers, 20 trucks, and 3 cargo planes to
ship anywhere.<br />
Unlike uranium, which is difficult to procure but not impossible to
steal and transport small amounts of, acquiring large-scale compute
requires the investment of resources in a relatively complicated and
visible process. Stakeholders, whether semiconductor firms, regulatory
bodies, or other involved entities, can accurately evaluate and trace
the overall quantity of these assets. For instance, if we monitor the
sales and distribution of chips, we know who possesses which
computational capacities and their intended applications. The complete
supply chain, from the semiconductor origins to the extensive data
centers harboring vast AI computational power, can be monitored, which
means it can be governed. By contrast, data acquisition and algorithmic
improvements can be done discreetly: possession of these within a
computing infrastructure can be concealed more easily than the
possession of the infrastructure itself.</p>
<h3 id="compute-is-excludable">Compute Is Excludable</h3>
<p>The second key characteristic that makes compute governable is its
excludability. Something is excludable if it is feasible to stop others
from using it. Most privately produced goods like automobiles are
excludable whereas others, such as clean air or street lighting, are
difficult to exclude people from consuming even if a government or
company doesn’t want to let them use it. Compute is excludable because a
few entities, such as the US and the EU, can control crucial parts of
its supply chain. This means that these actors can monitor and prevent
others from using compute.</p>
<p><strong>The compute supply chain makes monitoring easier.</strong> In
2023, the vast majority of advanced AI chips globally are crafted by a
single firm, Taiwan Semiconductor Manufacturing Company (TSMC). These
chips are based on designs from a few major companies, such as Nvidia
and Google, and TSMC’s production processes rely on photolithography
machines from a similarly monopolistic industry led by ASML <span
class="citation" data-cites="arnold2022eto"></span>. Entities such as
the US and EU can, therefore, regulate these companies to control the
supply of compute—if the supply chain dynamics do not change
dramatically over time <span class="citation"
data-cites="khan2021semiconductor"></span>. This simplifies the tracking
of frontier AI chips and enforcing of regulatory guidelines; it’s what
made the US export ban of cutting-edge AI chips to China in 2022
feasible. This example illustrates that these chips can be governed. By
contrast, data can be purchased from anywhere or found online, and
algorithmic advances are not excludable either, especially given the
open science and collaborative norms in the AI community.</p>
<p><strong>Frequent chip replacements means governance is effective
quickly.</strong> The price performance of AI chips is increasing
exponentially. With new chips frequently making recent products
obsolete, compute becomes more excludable. Historical trends show that
GPUs double their price performance approximately every 2.5 years <span
class="citation" data-cites="epoch2023mltrends"></span>. In conjunction
with the rapidly increasing demand for more compute, data centers
frequently refresh their chips and purchase vast quantities of new
compute regularly to retain competitiveness. This frequent chip turnover
offers a significant window for governance since regulations on new
chips will be relevant quickly.</p>
<h3 id="compute-is-quantifiable">Compute Is Quantifiable</h3>
<p>The third key characteristic that makes compute governable is its
quantifiability. Quantifiability refers to the ability to measure and
compare both the quantity and quality of resources. Metrics such as
FLOP/s serve as a yardstick for comparing computational capabilities
across different entities. If a developer has more chips of the same
type, we can accurately deduce that they have access to more compute,
which means we can use compute to set thresholds and monitor
compliance.</p>
<p><strong>Quantifiability facilitates clear threshold setting.</strong>
While chips and other forms of compute differ in many ways, they can all
be quantified in FLOP/s. This allows regulators to determine how
important it is to regulate a model that is being developed: models that
use large amounts of compute are likely more important to regulate.
Suppose a regulator aims to regulate new models that are large and
highly capable. A simple way to do this is to set a FLOP/s threshold,
above which more regulations, permissions, and scrutiny take effect. By
contrast, setting a threshold on dataset size is less meaningful:
quality of data varies enough that 25 GB of data could contain all the
text in Wikipedia or one high-definition photo album. Even worse,
algorithms are difficult to quantify at all.</p>
<p><strong>Quantifiability is key to monitoring compliance.</strong>
Beyond the creation of thresholds, quantifiability also helps us monitor
compliance. Given the physical nature and finite capacity of compute, we
can tell whether an actor has sufficient computational power from the
type and quantity of chips they possess. A regulator might require
organizations with at least 1000 chips at least as good as A100s to
submit themselves for additional auditing processes. A higher number of
chips directly correlates to more substantial computational
capabilities, unlike with algorithms where there is no comparable metric
and data for which metrics are much less precise. In addition to compute
being physical and so traceable, this enables the enforcement of rules
and thresholds.</p>
<h3 id="conclusions-about-compute-governance">Conclusions About Compute
Governance</h3>
<p><strong>Compute governance is a promising route to AI
governance.</strong> Compute is necessary for the development and
deployment of AIs, as well as being well-suited to governance,
especially relative to the other factors used in AI production. In
general, we see that compute governance is a promising lever for
ensuring the development of safe and beneficial AIs, allowing
governments to control distribution. Relative to governing algorithms
and datasets, the other factors used to produce AIs, governing compute
is promising because it is physical, excludable, and quantifiable.<br />
During this discussion, we have explored a wide variety of ways that
governments can set, monitor, and enforce standards and regulations.
Additionally, we have seen that international cooperation on compute
governance can help use its excludability to govern it well, assuming
entities like the US and EU can cooperate on governance. If factors such
as the controllability of the supply chain or requirement of large-scale
compute for highly capable models remain the same, then we might be
optimistic about using compute to govern AIs.<br />
While talking about compute governance, we have touched upon various
ideas about how to use compute to ensure companies produce safe AIs,
governments create and enforce regulations, and international
cooperation can control the compute supply chain. In the rest of this
chapter, we are going to further discuss governance tools aimed at
corporate, national, and international governance.</p>
